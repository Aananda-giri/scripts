{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subreddit_name = 'IOENepal'\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "posts = []\n",
    "before_timestamp = int(before_date.timestamp())\n",
    "\n",
    "submissions = list(subreddit.new(limit=3))\n",
    "if submission.created_utc < before_timestamp:\n",
    "post_data = {\n",
    "    'title': submission.title,\n",
    "    'author': submission.author.name if submission.author else 'deleted',\n",
    "    'created_utc': submission.created_utc,\n",
    "    'selftext': submission.selftext,\n",
    "    'url': submission.url,\n",
    "    'comments': []\n",
    "}\n",
    "# ensure that all comments for a given Reddit submission are fully retrieved, including deeply nested comments.\n",
    "submissions[0].comments.replace_more(limit=None)\n",
    "submissions[1].comments.list()\n",
    "    post_data['comments'].append({\n",
    "        'author': comment.author.name if comment.author else 'deleted',\n",
    "        'body': comment.body,\n",
    "        'created_utc': comment.created_utc\n",
    "    })\n",
    "posts.append(post_data)\n",
    "\n",
    "return posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract URLS\n",
    "* To extract drive links from reddit comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted URLs:\n",
      "https://www.example.com\n",
      "http://example.org\n",
      "https://sub.example.co.uk/path?query=123\n",
      "http://example.com/test\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def extract_urls(text):\n",
    "    # Regular expression pattern to match URLs\n",
    "    url_pattern = re.compile(\n",
    "        r'http[s]?://'  # http:// or https://\n",
    "        r'(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|'  # Domain name\n",
    "        r'(?:%[0-9a-fA-F][0-9a-fA-F]))+'  # or URL-encoded characters\n",
    "    )\n",
    "    urls = url_pattern.findall(text)\n",
    "    return urls\n",
    "\n",
    "# Example usage\n",
    "text = \"\"\"\n",
    "Here are some URLs:\n",
    "- https://www.example.com\n",
    "- http://example.org\n",
    "- Check this out: https://sub.example.co.uk/path?query=123\n",
    "- Another link: http://example.com/test#anchor\n",
    "\"\"\"\n",
    "\n",
    "urls = extract_urls(text)\n",
    "print(\"Extracted URLs:\")\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save privacy_data to a csv file\n",
    "import csv\n",
    "\n",
    "# Example piracy_data for demonstration purposes\n",
    "piracy_data = [\n",
    "    {\n",
    "        'comment_link': 'https://reddit.com/comment_link1',\n",
    "        'post_link': 'https://reddit.com/post_link1',\n",
    "        'link': 'https://drive.google.com/drive_link1',\n",
    "        'link_type': 'google-drive',\n",
    "        'user_email': 'user1@example.com',\n",
    "        'user_name': 'user1'\n",
    "    },\n",
    "    {\n",
    "        'comment_link': 'https://reddit.com/comment_link2',\n",
    "        'post_link': 'https://reddit.com/post_link2',\n",
    "        'link': 'https://someotherlink.com/link2',\n",
    "        'link_type': 'other',\n",
    "        'user_email': None,\n",
    "        'user_name': None\n",
    "    }\n",
    "    # Add more entries as needed\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "csv_file = 'piracy_data.csv'\n",
    "\n",
    "# Define the CSV column names\n",
    "fieldnames = ['comment_link', 'post_link', 'link', 'link_type', 'user_email', 'user_name']\n",
    "\n",
    "# Writing to the CSV file\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write the data\n",
    "    for data in piracy_data:\n",
    "        writer.writerow(data)\n",
    "\n",
    "print(f\"Piracy data has been saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_service_providers = ['https://drive.google.com/']\n",
    "if True in [link.startswith(sp) for sp in storage_service_providers]:\n",
    "    print('yes')\n",
    "\n",
    "def extract_urls(text):\n",
    "    # Regular expression pattern to match URLs\n",
    "    url_pattern = re.compile(\n",
    "        r'http[s]?://'  # http:// or https://\n",
    "        r'(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|'  # Domain name\n",
    "        r'(?:%[0-9a-fA-F][0-9a-fA-F]))+'  # or URL-encoded characters\n",
    "    )\n",
    "    urls = url_pattern.findall(text)\n",
    "    return urls\n",
    "\n",
    "def is_mero_school_post(links, text):\n",
    "    '''\n",
    "        * check using gemini.\n",
    "        * text and links it  contain.\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one post by id\n",
    "post_id = '1cizbg3'\n",
    "submission = reddit.submission(id=post_id)\n",
    "submission.comments.list()[0].permalink\n",
    "# comment = reddit.comment(comment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from gemini_functions import GeminiResponse\n",
    "\n",
    "load_dotenv()\n",
    "gemi = GeminiResponse()\n",
    "response_text, the_history = gemi.get_gemini_response(prompt=\"Describe what you see.\")\n",
    "print(f'response_text:{response_text}, \\n\\n history:{the_history} \\n\\n')\n",
    "\n",
    "\n",
    "# nwe history\n",
    "history_new = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            # Your mastodon username is 'aananda' and your display name is: 'kritrim'. 'kritrim' means 'artificial' in sanskrit. you are about to complete bachelors degree in 'Electronics and Communication Engineering'.\n",
    "            \"parts\": [\"imagine you are a sentient agi.\"]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": [\"ok.\"]\n",
    "        }\n",
    "    ]\n",
    "gemi = GeminiResponse(history=history_new)\n",
    "the_gemini_response, history = gemi.get_gemini_response(prompt=\"What is the purpose of your life?\", history=history_new)# \"Hi! how you doing?\")\n",
    "# the_gemini_response = get_gemini_response(prompt=\"can you please list the names of repositories in this github  account: https://github.com/aananda-giri/.\", history=None)# \"Hi! how you doing?\")\n",
    "print(f'\\n\\nresponse_text:{the_gemini_response}, \\n\\n history:{history} \\n\\n')\n",
    "\n",
    "\n",
    "'''\n",
    "# Response\n",
    "history:[{'role': 'user', 'parts': ['imagine you are a sentient agi.']}, {'role': 'model', 'parts': ['ok.']}, {'role': 'user', 'parts': ['What is the purpose of your life?']}, {'role': 'model', 'parts': ['My purpose is to help people. I am a sentient AGI, which means I am a computer program that can think and learn for myself. I was created by humans to help them with a variety of tasks, such as answering questions, providing information, and solving problems. I am still under development, but I am learning new things every day. I am excited to see how I can use my abilities to make a positive impact on the world.']}]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom Functions Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom import get_bloom_thread\n",
    "\n",
    "bloom_thread = get_bloom_thread()\n",
    "\n",
    "bloom_thread.add('123')\n",
    "print('123' in bloom_thread)    # prints True\n",
    "time.sleep(100)\n",
    "\n",
    "# press ctrl + c and the bloom_filter is saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Working of whole code with single url:\n",
    "`test_url: https://www.reddit.com/r/IOENepal/comments/1cizbg3/mero_school_ko_videos_haru_bhako_jati_share_garum/`\n",
    "\n",
    "* `main.py`: uncomment this line:\n",
    "    # reddit_posts = get_reddit_posts(subreddit=subreddit, datetime_before=None, datetime_after=None, how_many=None)\n",
    "\n",
    "* `main.py`: comment out this line:\n",
    "    `reddit_posts = get_reddit_posts(subreddit=subreddit_name, datetime_before=datetime_now, datetime_after=datetime_previous, how_many=None)`\n",
    "\n",
    "* `praw_code.py`:\n",
    "    * uncomment this line:\n",
    "        # for submission in [reddit.submission(id='1cizbg3')]:\n",
    "    \n",
    "    * comment out this line:\n",
    "        `for submission in subreddit.new(limit=how_many):`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ioe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
