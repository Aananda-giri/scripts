{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aananda-giri/scripts/blob/main/search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [source: chat-gpt](https://chat.openai.com/share/5551867b-a01d-4706-8a5c-ba2251c93112)\n",
        "\n",
        "* [colab](https://colab.research.google.com/drive/1x2J_i_gj4iMSxV5W-C0-PLe4AqJFF-9p?authuser=2)"
      ],
      "metadata": {
        "id": "y73HxZygwlRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple search\n",
        "\n",
        "# Sample corpus for simple search\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\"\n",
        "]\n",
        "\n",
        "# Function for simple search\n",
        "def simple_search(query, corpus):\n",
        "    results = []\n",
        "    for sentence in corpus:\n",
        "        if query.lower() in sentence.lower():\n",
        "            results.append(sentence)\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "query = \"Radio Frequency and Microwave\"\n",
        "results = simple_search(query, corpus)\n",
        "\n",
        "print(f\"Results containing '{query}':\")\n",
        "for result in results:\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuTE4LMP2pLQ",
        "outputId": "f0d01a38-ac77-45eb-a800-950e41337610"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results containing 'Radio Frequency and Microwave':\n",
            "I'm studying Radio Frequency and Microwave circuits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_search_term(search_term):\n",
        "    normalized_term = search_term.lower()  # Convert to lowercase for case insensitivity\n",
        "    normalized_term = re.sub(r'[^a-z\\s]', '', normalized_term)  # Remove non-alphabetic characters\n",
        "    normalized_term = re.sub(r'\\s+', ' ', normalized_term).strip()  # Remove extra spaces\n",
        "\n",
        "    # Handle specific terms or abbreviations\n",
        "    replacements = {\n",
        "        'radio frequency': 'rf',\n",
        "        'microwave': 'mw'\n",
        "        # Add more replacements as needed\n",
        "    }\n",
        "\n",
        "    for original, replacement in replacements.items():\n",
        "        normalized_term = normalized_term.replace(original, replacement)\n",
        "\n",
        "    return normalized_term\n",
        "\n",
        "def search(query, document):\n",
        "    normalized_query = normalize_search_term(query)\n",
        "    normalized_document = normalize_search_term(document)\n",
        "\n",
        "    return normalized_query in normalized_document\n",
        "\n",
        "# Example usage\n",
        "query = \"Radio Frequency and microwave\"\n",
        "document = \"Introduction to RF and Microwave Engineering\"\n",
        "result = search(query, document)\n",
        "\n",
        "if result:\n",
        "    print(\"Found a match!\")\n",
        "else:\n",
        "    print(\"No match found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0k5_7PfxIb8",
        "outputId": "f2709228-d850-46ff-8bde-76d9f9552c81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found a match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "UmxEwbv3wVfk",
        "outputId": "7b7f7545-cfba-41f8-8b76-8917a5419f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity with 'RF and Microwave engineering is fascinating.': 0.25191694498062134\n",
            "Similarity with 'Microwave frequencies are used in many applications.': -0.046546995639801025\n",
            "Similarity with 'The RF signal strength is measured in decibels.': 0.11139184981584549\n",
            "Similarity with 'I'm studying Radio Frequency and Microwave circuits.': 0.22794122993946075\n",
            "Similarity with 'EDC': 0.1180267333984375\n",
            "Similarity with 'Electronic device and Circuit': 1.0000001192092896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\nIn this code, we first define a sample corpus. We tokenize and lowercase the sentences. Then, we train a Word2Vec model on the tokenized sentences.\\n\\nThe similarity function calculates the cosine similarity between the vectors of the search term and the document content.\\n\\nKeep in mind that this is a simple example and may not cover all possible variations. Depending on your specific use case and the complexity of your data, you might need to fine-tune the Word2Vec model or consider using more advanced embedding techniques.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 1. Word Embeddings and Similarity with the popular Word2Vec model and Gensim library:\n",
        "\n",
        "# download necessary resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "# Sample corpus for training the Word2Vec model\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\",\n",
        "    \"EDC\",\n",
        "    \"Electronic device and Circuit\"\n",
        "]\n",
        "\n",
        "# Preprocess the corpus by tokenizing and lowercasing\n",
        "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "\n",
        "# Train a Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, sg=0)\n",
        "\n",
        "# Function to calculate similarity between two search terms\n",
        "def similarity(search_term, document):\n",
        "    search_vec = np.mean([model.wv[word] for word in search_term if word in model.wv], axis=0)\n",
        "    doc_vec = np.mean([model.wv[word] for word in document if word in model.wv], axis=0)\n",
        "    return np.dot(search_vec, doc_vec) / (np.linalg.norm(search_vec) * np.linalg.norm(doc_vec))\n",
        "\n",
        "# Example usage\n",
        "# query = \"Radio Frequency and Microwave\"\n",
        "query = \"Electronic device and Circuit\"\n",
        "# query = \"EDC\"\n",
        "for sentence in corpus:\n",
        "    sim = similarity(query.lower().split(), word_tokenize(sentence.lower()))\n",
        "    print(f\"Similarity with '{sentence}': {sim}\")\n",
        "\n",
        "\n",
        "\n",
        "'''\\n\\n\\n\\n\\n\n",
        "In this code, we first define a sample corpus. We tokenize and lowercase the sentences. Then, we train a Word2Vec model on the tokenized sentences.\n",
        "\n",
        "The similarity function calculates the cosine similarity between the vectors of the search term and the document content.\n",
        "\n",
        "Keep in mind that this is a simple example and may not cover all possible variations. Depending on your specific use case and the complexity of your data, you might need to fine-tune the Word2Vec model or consider using more advanced embedding techniques.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAoLxvbcwVfq",
        "outputId": "a042d369-b8a7-4519-8b68-000fe3cb50c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: 0.117*\"rf\" + 0.078*\"strength\" + 0.077*\"signal\" + 0.077*\"decibels\" + 0.075*\"microwave\" + 0.074*\"measured\" + 0.070*\"engineering\" + 0.067*\"fascinating\" + 0.049*\"frequencies\" + 0.045*\"many\"\n",
            "Topic 1: 0.134*\"microwave\" + 0.068*\"circuits\" + 0.068*\"radio\" + 0.067*\"studying\" + 0.067*\"frequency\" + 0.067*\"'m\" + 0.064*\"used\" + 0.062*\"applications\" + 0.061*\"many\" + 0.058*\"frequencies\"\n",
            "Topic distribution for 'RF and Microwave': [(0, 0.5527477), (1, 0.4472523)]\n"
          ]
        }
      ],
      "source": [
        "# 2. Latent Dirichlet Allocation (LDA) for topic modeling using the popular library Gensim:\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Sample corpus for topic modeling\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\"\n",
        "]\n",
        "\n",
        "# Preprocessing: Tokenization, lowercase, removing punctuation and stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = string.punctuation\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations]\n",
        "    return tokens\n",
        "\n",
        "tokenized_corpus = [preprocess_text(sentence) for sentence in corpus]\n",
        "\n",
        "# Create a dictionary and a corpus\n",
        "dictionary = corpora.Dictionary(tokenized_corpus)\n",
        "corpus_bow = [dictionary.doc2bow(text) for text in tokenized_corpus]\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(corpus_bow, num_topics=2, id2word=dictionary)\n",
        "\n",
        "# Print the topics\n",
        "for idx, topic in lda_model.print_topics():\n",
        "    print(f\"Topic {idx}: {topic}\")\n",
        "\n",
        "# Example usage for searching for topics\n",
        "search_query = \"RF and Microwave\"\n",
        "query_bow = dictionary.doc2bow(preprocess_text(search_query))\n",
        "\n",
        "# Get the topic distribution for the query\n",
        "query_topic_distribution = lda_model[query_bow]\n",
        "print(f\"Topic distribution for '{search_query}': {query_topic_distribution}\")\n",
        "\n",
        "\n",
        "# '''\n",
        "# In this code:\n",
        "\n",
        "# We start with a sample corpus.\n",
        "# We preprocess the text by tokenizing, converting to lowercase, removing punctuation, and eliminating stopwords.\n",
        "# We create a dictionary and a Bag of Words representation of the corpus.\n",
        "# We train an LDA model with 2 topics. You can adjust the num_topics parameter as needed.\n",
        "# We print out the topics discovered by the model.\n",
        "# We demonstrate how to use the model for a search query.\n",
        "# Keep in mind that topic modeling may not always produce interpretable results, and the number of topics (num_topics) may need to be adjusted based on the nature of your corpus. Additionally, more sophisticated preprocessing steps and techniques like coherence score evaluation can be used to enhance the quality of topics.\n",
        "# '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyz0QCmQwVfr",
        "outputId": "5bec54b2-9a11-4b22-eebc-59d2d8c40e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity with 'RF and Microwave engineering is fascinating.': 0.28604976898651346\n",
            "Similarity with 'Microwave frequencies are used in many applications.': 0.09533655557814368\n",
            "Similarity with 'The RF signal strength is measured in decibels.': 0.0\n",
            "Similarity with 'I'm studying Radio Frequency and Microwave circuits.': 0.7760843129566192\n"
          ]
        }
      ],
      "source": [
        "# 3. TF-IDF and Cosine Similarity to handle text variations\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Sample corpus for TF-IDF and similarity\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\"\n",
        "]\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Create TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Function to calculate similarity between two search terms\n",
        "def similarity(search_term, document):\n",
        "    search_tfidf = tfidf_vectorizer.transform([search_term])\n",
        "    doc_tfidf = tfidf_vectorizer.transform([document])\n",
        "    return cosine_similarity(search_tfidf, doc_tfidf)[0][0]\n",
        "\n",
        "# Example usage\n",
        "query = \"Radio Frequency and Microwave\"\n",
        "for sentence in corpus:\n",
        "    sim = similarity(query, sentence)\n",
        "    print(f\"Similarity with '{sentence}': {sim}\")\n",
        "\n",
        "\n",
        "# '''\n",
        "# In this code:\n",
        "\n",
        "# We start with a sample corpus.\n",
        "# We initialize a TF-IDF vectorizer.\n",
        "# We create a TF-IDF matrix for the corpus.\n",
        "# We define a function similarity that calculates the cosine similarity between the TF-IDF vectors of the search term and the document content.\n",
        "# We use the function to compare the query with each sentence in the corpus.\n",
        "# Keep in mind that this is a basic example and may require further refinement depending on your specific use case. For instance, you might want to experiment with different preprocessing steps or explore more advanced techniques for handling text variations.\n",
        "# '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpUM5QbYwVfs",
        "outputId": "d7accf14-7c9f-4583-9a94-d8c8b644fe09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nearest neighbor to 'Radio Frequency and Microwave' is: I'm studying Radio Frequency and Microwave circuits.\n"
          ]
        }
      ],
      "source": [
        "# 4. Nearest Neighbor Search\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Sample corpus for nearest neighbor search\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\"\n",
        "]\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Create TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Initialize NearestNeighbors for nearest neighbor search\n",
        "n_neighbors = 1  # Set the number of neighbors to find\n",
        "knn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='brute', metric='cosine')\n",
        "knn.fit(tfidf_matrix)\n",
        "\n",
        "# Function to find nearest neighbor to a search term\n",
        "def nearest_neighbor(search_term):\n",
        "    search_vector = tfidf_vectorizer.transform([search_term])\n",
        "    _, indices = knn.kneighbors(search_vector)\n",
        "    return corpus[indices[0][0]]\n",
        "\n",
        "# Example usage\n",
        "query = \"Radio Frequency and Microwave\"\n",
        "result = nearest_neighbor(query)\n",
        "\n",
        "print(f\"The nearest neighbor to '{query}' is: {result}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748,
          "referenced_widgets": [
            "90b13da9b3ac489390bcf046742ff83a",
            "7f5ec1343e304ead98debdb4701b24f3",
            "a09ab46d53ab4f53ac824ccace1ae58b",
            "c707a919332c4e5ea7e6a73acdff6e41",
            "89acc2b88f584efbaab53b23b3d78f06",
            "42380bda14954ae386f21d7ac8f44af5",
            "11f9d879ba85428ba3108490c0007e2f",
            "c142d849ef7e4719b0532804380cde62",
            "9261ae8a8e1c42a0b93465cf0d6cd5bd",
            "158c570a1b464f859847a29b5521e5d0",
            "dcfa57f62004413cbde3f2f23f05e738"
          ]
        },
        "id": "ZB_H7UZtwVfs",
        "outputId": "a6f3acf3-04e4-457f-ce9c-14e84c087ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90b13da9b3ac489390bcf046742ff83a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is RF and Microwave engineering?\n",
            "Answer: fascinating\n",
            "\n",
            "Question: How are Microwave frequencies used?\n",
            "Answer: in many applications\n",
            "\n",
            "Question: How is RF signal strength measured?\n",
            "Answer: in decibels\n",
            "\n",
            "Question: What are you studying?\n",
            "Answer: Radio Frequency and Microwave circuits\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nExplanation:\\n\\nWe load a pre-trained BERT model and tokenizer that is fine-tuned for the SQuAD dataset. This model is capable of question answering tasks.\\n\\nWe define a function answer_question that takes a question and a context and returns the answer using BERT.\\n\\nWe provide a sample context related to RF and Microwave engineering.\\n\\nWe define a list of example questions.\\n\\nWe loop through the questions, use the answer_question function to find the answers, and print them out.\\n\\nKeep in mind that this is a simplified example. Fine-tuning BERT for specific tasks may require additional steps such as creating a suitable dataset and training the model on it. The Hugging Face library provides tools for these tasks as well.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 5. BERT and Fine-tuning to handle text variations without explictly specifying replacement text\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained BERT model for question answering\n",
        "qa_pipeline = pipeline('question-answering', model='bert-large-uncased-whole-word-masking-finetuned-squad', tokenizer='bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "# Sample context\n",
        "context = (\n",
        "    \"RF and Microwave engineering is fascinating. Microwave frequencies are used in many applications. \"\n",
        "    \"The RF signal strength is measured in decibels. I'm studying Radio Frequency and Microwave circuits.\"\n",
        ")\n",
        "\n",
        "# Example questions\n",
        "questions = [\n",
        "    \"What is RF and Microwave engineering?\",\n",
        "    \"How are Microwave frequencies used?\",\n",
        "    \"How is RF signal strength measured?\",\n",
        "    \"What are you studying?\"\n",
        "]\n",
        "\n",
        "# Answer the questions\n",
        "for question in questions:\n",
        "    answer = qa_pipeline(question=question, context=context)\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer['answer']}\\n\")\n",
        "\n",
        "\n",
        "'''\n",
        "Explanation:\n",
        "\n",
        "We load a pre-trained BERT model and tokenizer that is fine-tuned for the SQuAD dataset. This model is capable of question answering tasks.\n",
        "\n",
        "We define a function answer_question that takes a question and a context and returns the answer using BERT.\n",
        "\n",
        "We provide a sample context related to RF and Microwave engineering.\n",
        "\n",
        "We define a list of example questions.\n",
        "\n",
        "We loop through the questions, use the answer_question function to find the answers, and print them out.\n",
        "\n",
        "Keep in mind that this is a simplified example. Fine-tuning BERT for specific tasks may require additional steps such as creating a suitable dataset and training the model on it. The Hugging Face library provides tools for these tasks as well.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "3HR_3M2nwVft",
        "outputId": "7b72810f-1dbd-45ce-ff43-b17adcff0c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1:\n",
            "RF and Microwave engineering is fascinating.\n",
            "The RF signal strength is measured in decibels.\n",
            "\n",
            "Cluster 2:\n",
            "Microwave frequencies are used in many applications.\n",
            "I'm studying Radio Frequency and Microwave circuits.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIn this code:\\n\\nWe start with a sample corpus.\\nWe define a preprocessing function that tokenizes, converts to lowercase, removes punctuation, stopwords, and then joins the tokens back into a sentence.\\nWe preprocess the corpus.\\nWe initialize a TF-IDF vectorizer and create a TF-IDF matrix for the preprocessed corpus.\\nWe apply K-Means clustering with a specified number of clusters.\\nWe group the sentences by their assigned cluster.\\nFinally, we print out the clusters.\\nPlease note that the number of clusters (num_clusters) is set arbitrarily in this example. In practice, you might need to experiment with different numbers of clusters to find the optimal grouping for your specific data.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 6. Clustering to handle text variations without explictly specifying replacement text\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Sample corpus for clustering\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\"\n",
        "]\n",
        "\n",
        "# Preprocessing: Tokenization, lowercase, removing punctuation and stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = string.punctuation\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "preprocessed_corpus = [preprocess_text(sentence) for sentence in corpus]\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Create TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_corpus)\n",
        "\n",
        "# Apply K-Means clustering\n",
        "num_clusters = 2  # Set the number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "clusters = kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "# Group sentences by cluster\n",
        "clustered_sentences = [[] for _ in range(num_clusters)]\n",
        "for i, cluster in enumerate(clusters):\n",
        "    clustered_sentences[cluster].append(corpus[i])\n",
        "\n",
        "# Print clusters\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    for sentence in cluster:\n",
        "        print(sentence)\n",
        "    print()\n",
        "\n",
        "\n",
        "'''\n",
        "In this code:\n",
        "\n",
        "We start with a sample corpus.\n",
        "We define a preprocessing function that tokenizes, converts to lowercase, removes punctuation, stopwords, and then joins the tokens back into a sentence.\n",
        "We preprocess the corpus.\n",
        "We initialize a TF-IDF vectorizer and create a TF-IDF matrix for the preprocessed corpus.\n",
        "We apply K-Means clustering with a specified number of clusters.\n",
        "We group the sentences by their assigned cluster.\n",
        "Finally, we print out the clusters.\n",
        "Please note that the number of clusters (num_clusters) is set arbitrarily in this example. In practice, you might need to experiment with different numbers of clusters to find the optimal grouping for your specific data.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSuirmm4wVft",
        "outputId": "34af93f8-4028-4571-d00e-c99935521dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences similar to 'RF and Microwave':\n",
            "['RF and Microwave engineering is fascinating.', <tf.Tensor: shape=(), dtype=float32, numpy=0.60963064>]\n",
            "[\"I'm studying Radio Frequency and Microwave circuits.\", <tf.Tensor: shape=(), dtype=float32, numpy=0.513118>]\n",
            "['Microwave frequencies are used in many applications.', <tf.Tensor: shape=(), dtype=float32, numpy=0.31462774>]\n",
            "['The RF signal strength is measured in decibels.', <tf.Tensor: shape=(), dtype=float32, numpy=0.2823853>]\n"
          ]
        }
      ],
      "source": [
        "# 7. Semantic Search with Sentence Embedding\n",
        "\n",
        "# we'll use Universal Sentence Encoder (USE)\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load Universal Sentence Encoder\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Sample corpus for semantic search\n",
        "corpus = [\n",
        "    \"RF and Microwave engineering is fascinating.\",\n",
        "    \"Microwave frequencies are used in many applications.\",\n",
        "    \"The RF signal strength is measured in decibels.\",\n",
        "    \"I'm studying Radio Frequency and Microwave circuits.\"\n",
        "]\n",
        "\n",
        "# Encode sentences\n",
        "sentence_embeddings = embed(corpus)\n",
        "\n",
        "# Function to find semantically similar sentences\n",
        "def find_similar_sentences(query, threshold=0.2):\n",
        "    query_embedding = embed([query])[0]\n",
        "    similarity_scores = tf.tensordot(query_embedding, sentence_embeddings, axes=[[0], [1]])\n",
        "    similar_sentences = [[corpus[i], similarity_scores[i]] for i in tf.argsort(similarity_scores, direction='DESCENDING') if similarity_scores[i] > threshold]\n",
        "    return similar_sentences\n",
        "\n",
        "# Example usage\n",
        "query = \"RF and Microwave\"\n",
        "similar_sentences = find_similar_sentences(query)\n",
        "\n",
        "print(f\"Sentences similar to '{query}':\")\n",
        "for sentence in similar_sentences:\n",
        "    print(sentence)\n",
        "\n",
        "# '''\n",
        "# Explanation:\n",
        "\n",
        "# We load the Universal Sentence Encoder from TensorFlow Hub. This model converts sentences into high-dimensional embeddings that capture their semantic meaning.\n",
        "\n",
        "# We define a sample corpus.\n",
        "\n",
        "# We encode the sentences using the Universal Sentence Encoder.\n",
        "\n",
        "# We define a function find_similar_sentences that takes a query and a threshold for similarity scores. It computes the similarity between the query and each sentence in the corpus and returns sentences with similarity scores above the threshold.\n",
        "\n",
        "# We use the function to find sentences similar to the given query.\n",
        "\n",
        "# Keep in mind that the threshold value may need to be adjusted based on your specific use case and data. This example provides a basic illustration of how to perform semantic search using sentence embeddings.\n",
        "# '''"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90b13da9b3ac489390bcf046742ff83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f5ec1343e304ead98debdb4701b24f3",
              "IPY_MODEL_a09ab46d53ab4f53ac824ccace1ae58b",
              "IPY_MODEL_c707a919332c4e5ea7e6a73acdff6e41"
            ],
            "layout": "IPY_MODEL_89acc2b88f584efbaab53b23b3d78f06"
          }
        },
        "7f5ec1343e304ead98debdb4701b24f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42380bda14954ae386f21d7ac8f44af5",
            "placeholder": "​",
            "style": "IPY_MODEL_11f9d879ba85428ba3108490c0007e2f",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "a09ab46d53ab4f53ac824ccace1ae58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c142d849ef7e4719b0532804380cde62",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9261ae8a8e1c42a0b93465cf0d6cd5bd",
            "value": 466062
          }
        },
        "c707a919332c4e5ea7e6a73acdff6e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158c570a1b464f859847a29b5521e5d0",
            "placeholder": "​",
            "style": "IPY_MODEL_dcfa57f62004413cbde3f2f23f05e738",
            "value": " 466k/466k [00:00&lt;00:00, 20.0MB/s]"
          }
        },
        "89acc2b88f584efbaab53b23b3d78f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42380bda14954ae386f21d7ac8f44af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f9d879ba85428ba3108490c0007e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c142d849ef7e4719b0532804380cde62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9261ae8a8e1c42a0b93465cf0d6cd5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "158c570a1b464f859847a29b5521e5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfa57f62004413cbde3f2f23f05e738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}